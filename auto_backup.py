#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨å¤‡ä»½è„šæœ¬
å®šæœŸå¤‡ä»½ACMå®éªŒå®¤ç³»ç»Ÿæ•°æ®ï¼Œç¡®ä¿æ•°æ®å®‰å…¨
"""

import os
import shutil
import sqlite3
import json
import schedule
import time
from datetime import datetime, timedelta
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('backup.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

DATABASE = 'acm_lab.db'
BACKUP_DIR = 'data_backups'
MAX_BACKUPS = 10  # ä¿ç•™æœ€è¿‘10ä¸ªå¤‡ä»½

def ensure_backup_dir():
    """ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨"""
    if not os.path.exists(BACKUP_DIR):
        os.makedirs(BACKUP_DIR)
        logger.info(f"åˆ›å»ºå¤‡ä»½ç›®å½•: {BACKUP_DIR}")

def cleanup_old_backups():
    """æ¸…ç†è¿‡æœŸçš„å¤‡ä»½æ–‡ä»¶"""
    try:
        ensure_backup_dir()
        
        # è·å–æ‰€æœ‰å¤‡ä»½æ–‡ä»¶
        backup_files = []
        for file in os.listdir(BACKUP_DIR):
            if file.startswith('acm_lab_backup_') and file.endswith('.db'):
                file_path = os.path.join(BACKUP_DIR, file)
                backup_files.append((file_path, os.path.getctime(file_path)))
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åº
        backup_files.sort(key=lambda x: x[1], reverse=True)
        
        # åˆ é™¤è¶…è¿‡MAX_BACKUPSçš„æ–‡ä»¶
        if len(backup_files) > MAX_BACKUPS:
            for file_path, _ in backup_files[MAX_BACKUPS:]:
                os.remove(file_path)
                logger.info(f"åˆ é™¤è¿‡æœŸå¤‡ä»½: {os.path.basename(file_path)}")
                
    except Exception as e:
        logger.error(f"æ¸…ç†å¤‡ä»½æ–‡ä»¶å¤±è´¥: {e}")

def backup_database():
    """å¤‡ä»½æ•°æ®åº“"""
    try:
        if not os.path.exists(DATABASE):
            logger.warning(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {DATABASE}")
            return False
            
        ensure_backup_dir()
        
        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_file = os.path.join(BACKUP_DIR, f'acm_lab_backup_{timestamp}.db')
        
        # å¤åˆ¶æ•°æ®åº“æ–‡ä»¶
        shutil.copy2(DATABASE, backup_file)
        
        # éªŒè¯å¤‡ä»½æ–‡ä»¶
        if os.path.exists(backup_file):
            file_size = os.path.getsize(backup_file) / 1024  # KB
            logger.info(f"æ•°æ®åº“å¤‡ä»½æˆåŠŸ: {backup_file} ({file_size:.1f} KB)")
            
            # æ¸…ç†æ—§å¤‡ä»½
            cleanup_old_backups()
            return True
        else:
            logger.error("å¤‡ä»½æ–‡ä»¶åˆ›å»ºå¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"æ•°æ®åº“å¤‡ä»½å¤±è´¥: {e}")
        return False

def get_database_info():
    """è·å–æ•°æ®åº“ä¿¡æ¯"""
    try:
        if not os.path.exists(DATABASE):
            return None
            
        conn = sqlite3.connect(DATABASE)
        conn.row_factory = sqlite3.Row
        
        # è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯
        tables_info = {}
        cursor = conn.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = [row[0] for row in cursor.fetchall()]
        
        for table in tables:
            try:
                cursor = conn.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                tables_info[table] = count
            except:
                tables_info[table] = 0
        
        conn.close()
        
        return {
            'file_size': os.path.getsize(DATABASE) / 1024,  # KB
            'tables': tables_info,
            'total_records': sum(tables_info.values())
        }
        
    except Exception as e:
        logger.error(f"è·å–æ•°æ®åº“ä¿¡æ¯å¤±è´¥: {e}")
        return None

def scheduled_backup():
    """å®šæ—¶å¤‡ä»½ä»»åŠ¡"""
    logger.info("å¼€å§‹æ‰§è¡Œå®šæ—¶å¤‡ä»½ä»»åŠ¡")
    
    # è·å–å¤‡ä»½å‰çš„æ•°æ®åº“ä¿¡æ¯
    db_info = get_database_info()
    if db_info:
        logger.info(f"æ•°æ®åº“ä¿¡æ¯: {db_info['total_records']} æ¡è®°å½•, {db_info['file_size']:.1f} KB")
    
    # æ‰§è¡Œå¤‡ä»½
    success = backup_database()
    
    if success:
        logger.info("å®šæ—¶å¤‡ä»½ä»»åŠ¡å®Œæˆ")
    else:
        logger.error("å®šæ—¶å¤‡ä»½ä»»åŠ¡å¤±è´¥")

def manual_backup():
    """æ‰‹åŠ¨å¤‡ä»½"""
    print("ğŸš€ å¼€å§‹æ‰‹åŠ¨å¤‡ä»½...")
    
    db_info = get_database_info()
    if db_info:
        print(f"ğŸ“Š æ•°æ®åº“ä¿¡æ¯:")
        print(f"   æ–‡ä»¶å¤§å°: {db_info['file_size']:.1f} KB")
        print(f"   æ€»è®°å½•æ•°: {db_info['total_records']}")
        print(f"   è¡¨è¯¦æƒ…:")
        for table, count in db_info['tables'].items():
            if count > 0:
                print(f"      {table}: {count} æ¡")
    
    success = backup_database()
    
    if success:
        print("âœ… æ‰‹åŠ¨å¤‡ä»½å®Œæˆï¼")
        
        # æ˜¾ç¤ºå¤‡ä»½æ–‡ä»¶åˆ—è¡¨
        print(f"\nğŸ“ å¤‡ä»½æ–‡ä»¶åˆ—è¡¨:")
        backup_files = []
        for file in os.listdir(BACKUP_DIR):
            if file.startswith('acm_lab_backup_') and file.endswith('.db'):
                file_path = os.path.join(BACKUP_DIR, file)
                file_size = os.path.getsize(file_path) / 1024
                create_time = datetime.fromtimestamp(os.path.getctime(file_path))
                backup_files.append((file, file_size, create_time))
        
        backup_files.sort(key=lambda x: x[2], reverse=True)
        for i, (file, size, time) in enumerate(backup_files[:5], 1):
            print(f"   {i}. {file} ({size:.1f} KB) - {time.strftime('%Y-%m-%d %H:%M:%S')}")
    else:
        print("âŒ æ‰‹åŠ¨å¤‡ä»½å¤±è´¥ï¼")

def start_scheduler():
    """å¯åŠ¨å®šæ—¶å¤‡ä»½è°ƒåº¦å™¨"""
    # æ¯å¤©å‡Œæ™¨2ç‚¹å¤‡ä»½
    schedule.every().day.at("02:00").do(scheduled_backup)
    
    # æ¯12å°æ—¶å¤‡ä»½ä¸€æ¬¡
    schedule.every(12).hours.do(scheduled_backup)
    
    logger.info("å¤‡ä»½è°ƒåº¦å™¨å·²å¯åŠ¨")
    logger.info("å®šæ—¶ä»»åŠ¡: æ¯å¤©å‡Œæ™¨2ç‚¹ å’Œ æ¯12å°æ—¶æ‰§è¡Œå¤‡ä»½")
    
    try:
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    except KeyboardInterrupt:
        logger.info("å¤‡ä»½è°ƒåº¦å™¨å·²åœæ­¢")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ACMå®éªŒå®¤æ•°æ®åº“è‡ªåŠ¨å¤‡ä»½å·¥å…·')
    parser.add_argument('action', nargs='?', choices=['backup', 'schedule', 'info'], 
                       default='backup', help='æ‰§è¡Œçš„æ“ä½œ')
    
    args = parser.parse_args()
    
    if args.action == 'backup':
        manual_backup()
    elif args.action == 'schedule':
        start_scheduler()
    elif args.action == 'info':
        db_info = get_database_info()
        if db_info:
            print(f"ğŸ“Š æ•°æ®åº“ä¿¡æ¯:")
            print(f"   æ–‡ä»¶: {DATABASE}")
            print(f"   å¤§å°: {db_info['file_size']:.1f} KB")
            print(f"   æ€»è®°å½•: {db_info['total_records']}")
            print(f"   è¡¨ç»Ÿè®¡:")
            for table, count in sorted(db_info['tables'].items()):
                if count > 0:
                    print(f"      {table}: {count} æ¡")
        else:
            print("âŒ æ— æ³•è·å–æ•°æ®åº“ä¿¡æ¯")

if __name__ == '__main__':
    main()
